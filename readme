--- #Assignment 2 ---
# Student: Roger Bassons Renart & Andrew Choliy
# NetID: rb1018 & ...
# Tested on grep.cs.rutgers.edu

#Issues with our code

Our code, with virtual memory enabled, does not work with Benchmarking code.
Our current design can only hold a memory as big as the physical region reserved
to threads (per thread).


#Overview

In order to implement our memory managment mechanism we use a Linked List to keep
track of both pages and dynamic allocations. All the bookkeeping is done inside
the 8MB char array.

The first ~2MB are reserved for OS allocations. This reserved space is a Linked
List of dynamic size elements.

After the OS reserved space and until the last 4 pages we have the memory region
used for the threads. This region is initialized with pages (fixed size
elements) with the help of a Linked List. Then inside each page we have another
Linked List that can be used by the page's thread to allocate dynamic size
elements.

The last 4 pages are another Linked List that is used by all the threads as a
shared region.

#Pages

When a thread tries to allocate more memory than a page can hold, the OS will
allocate extra pages as needed. This pages are grouped in a "big page" while the
thread is running/accessing memory. When this thread is enqueued to the OS
queue, this "big page" is split into pages to make it easier to manage pages
(this way we can assume all the pages are the same size).

Once the thread is scheduled to run again the "splitted" pages are grouped again
into one "big page".


# Virtual Memory
To simulate virtual memory we swap pages to the beggining of the memory
(beggining of threads region).

This design makes impossible to give a thread a virtual memory bigger than the
physical memory.


#Swap & Replacing


#Tests

We don't know why, but this tests only work if compiled "by hand" without Makefile.

* test4: General test for virtual memory
* test5: Allocations bigger than a page test
* test6: Splitting and grouping test
* test7: Shared memory test




--- #Assignment 1 ---

# Student: Roger Bassons Renart
# NetID: rb1018
# Tested on grep.cs.rutgers.edu

## Implementation overview

---

* I implemented a RR scheduler that priority to jobs that finish before the fixed 
time quanta (25ms). Around every 4 seconds(~150 scheduler runs). I reorder the 
run queue giving priority to the oldest jobs no matter what. This could be improved 
(with more time) to avoid that if there are a lot of low priority jobs they 
don't starve to run. The way the scheduler works causes priority inversion: oldest
threads (low priority) get pushed to the front of the running queue every 4
seconds to aviod starvation.

* My implementation of the waiting queue is not global: there is a waiting queue for
each mutex. This way, a thread that is waiting for a mutex is never scheduled to run.
Once the mutex is released, the next thread waiting for the mutex is pushed to the
run queue. If no threads are waiting for the mutex, the mutex is completely unlocked.
This mutex implementation doesn't induce priority inversion because waiting threads
aren't scheduled to run, therefore waiting threads' priority is never lowered.

* I developed a Linked List to implement thread queues.

* In order to aviod being interrupted while running the scheduler I use sigprocmask 
function to block and ignore the interrupt signal.

* Scheduler variables, i.e. run queue, are allocated on the heap(malloc) instead of the 
stack to avoid losing changes when switching context.

* In addition to the pthreads implementation you will find three test programs 
that check the correctness of the implementation:

  - test1.c: checks pthread_create, pthread_exit, pthread_join among others.

  - test2.c: checks scheduler and pthread_yield among others (never ends).

  - test3.c: checks mutex among others.


## Benchmarking

---

I couldn't use the latest benchmarking code from the TA because unfortunately the
latest code was released too close to the assignment deadline and I've got a very tight
schedule. I modified the first versions of the benchmarking code to be able to
run it:

### vectorMultiply

threads 1000  
array size 100000000

my_pthread_t time: 31.901s

pthread_t    time: 25.489s


### parallelCal

threads 1000
C size 10000000
R size 100000

my_pthread_t
real 1m07.584s

pthread_t
real 26.239s
